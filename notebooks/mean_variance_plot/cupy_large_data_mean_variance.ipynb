{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b29f7b-2d40-4437-b900-097a11b51005",
   "metadata": {},
   "source": [
    "In this notebook, I demonstrate how to efficiently compute the mean and variance of a large dataset using CuPy, leveraging GPU acceleration for handling high-dimensional data. The dataset used is a colon data example from the 10x Genomics website. This notebook showcases the performance advantages of CuPy when working with large-scale genomic data, and includes visualizations of the calculated mean-variance relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db71f8c-0106-449f-a7f9-69b05292b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import cupy as cp\n",
    "import cupyx\n",
    "from cupyx.scipy.sparse import csr_matrix \n",
    "import os\n",
    "import time\n",
    "import rapids_singlecell as rsc\n",
    "import numpy as np\n",
    "import rmm\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "import cupy\n",
    "\n",
    "rmm.reinitialize(\n",
    "    managed_memory=False,  # Allows oversubscription\n",
    "    pool_allocator=False,  # default is False\n",
    "    devices=0,  # GPU device IDs to register. By default registers only GPU 0.\n",
    ")\n",
    "cp.cuda.set_allocator(rmm_cupy_allocator)\n",
    "import zarr\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy\n",
    "import anndata\n",
    "from collections import OrderedDict\n",
    "from rsc_functions.utility.applyqc import applyqc\n",
    "from rsc_functions.reports.plot import plot_spatial,plot_spatial_data, plot_dist\n",
    "from rsc_functions.utility.rank_genes_groups import return_markers,rank_genes_groups\n",
    "from rsc_functions.reports.plot import plot_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf2b67-54d2-4a67-96e7-e231eb57db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_016 = \"/data/kanferg/Sptial_Omics/playGround/Data/Visium_HD_Human_Colon_Cancer_binned_outputs/binned_outputs/square_016um\"\n",
    "pathout = \"/data/kanferg/Sptial_Omics/SpatialOmicsToolkit/out_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c4bf4-8cf7-438b-a8d9-17b96a99618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet_to_csv(path):\n",
    "    '''\n",
    "    Converts a Parquet file to a CSV file if the CSV file does not already exist.\n",
    "    '''\n",
    "    file_path = os.path.join(path,'spatial/tissue_positions_list.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        df = pd.read_parquet(os.path.join(path,'spatial/tissue_positions.parquet'))\n",
    "        # Write to a CSV file\n",
    "        df.to_csv(os.path.join(path,'spatial/tissue_positions_list.csv'), index=False)\n",
    "    return\n",
    "parquet_to_csv(path_016)\n",
    "andata = sc.read_visium(path=path_016)\n",
    "rsc.get.anndata_to_GPU(andata)\n",
    "andata.obsm['spatial'] = np.array(andata.obsm['spatial'], dtype=np.float64)\n",
    "andata.var_names_make_unique()\n",
    "andata.uns['config'] = OrderedDict()\n",
    "andata.uns[\"config\"][\"secondary_var_names\"] = andata.var_names\n",
    "rsc.pp.flag_gene_family(andata, gene_family_name=\"MT\", gene_family_prefix=\"MT-\")\n",
    "rsc.pp.calculate_qc_metrics(andata, qc_vars=[\"MT\"])\n",
    "rsc.pp.filter_cells(andata, min_count=1000,qc_var = 'total_counts')\n",
    "rsc.pp.filter_genes(andata, min_count=50)\n",
    "rsc.pp.filter_genes(andata, max_count=50_000)\n",
    "andata.layers['counts'] = andata.X.copy()\n",
    "rsc.pp.normalize_total(andata)\n",
    "# rsc.pp.log1p(andata)\n",
    "# andata.layers['log'] = andata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0d04d-2121-4bba-81b5-0a7d9a0001cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import cupyx.scipy.sparse as sparse\n",
    "\n",
    "# Assuming your sparse matrix is in CSR format\n",
    "sparse_data = andata.X  # Example: andata.X as the sparse matrix in CSR format (CSR format)\n",
    "\n",
    "def sparse_mean_variance_covariance_csr(sparse_data):\n",
    "    # Get non-zero data from the sparse matrix\n",
    "    data = sparse_data.data        # Non-zero elements\n",
    "    indices = sparse_data.indices  # Column indices of the non-zero elements\n",
    "    indptr = sparse_data.indptr    # Points to the start of each row in data\n",
    "    \n",
    "    # Initialize arrays for mean, variance, and covariance\n",
    "    num_cols = sparse_data.shape[1]\n",
    "    col_sum = cp.zeros(num_cols)\n",
    "    col_count = cp.zeros(num_cols)\n",
    "    col_sum_sq_diff = cp.zeros(num_cols)  # For variance calculation\n",
    "    \n",
    "    # Iterate over rows\n",
    "    for i in range(sparse_data.shape[0]):\n",
    "        # Get the non-zero elements in the current row\n",
    "        row_start = indptr[i]\n",
    "        row_end = indptr[i + 1]\n",
    "        row_data = data[row_start:row_end]\n",
    "        row_indices = indices[row_start:row_end]\n",
    "        \n",
    "        # Update column sums and counts for the non-zero elements\n",
    "        col_sum[row_indices] += row_data\n",
    "        col_count[row_indices] += 1\n",
    "    \n",
    "    # Compute mean: sum divided by the count of non-zero elements\n",
    "    col_mean = col_sum / col_count\n",
    "    \n",
    "    # Compute variance: (data - mean)^2 sum\n",
    "    for i in range(sparse_data.shape[0]):\n",
    "        # Get the non-zero elements in the current row\n",
    "        row_start = indptr[i]\n",
    "        row_end = indptr[i + 1]\n",
    "        row_data = data[row_start:row_end]\n",
    "        row_indices = indices[row_start:row_end]\n",
    "        \n",
    "        # Compute squared difference from the mean\n",
    "        sq_diff = (row_data - col_mean[row_indices]) ** 2\n",
    "        col_sum_sq_diff[row_indices] += sq_diff\n",
    "    \n",
    "    # Compute variance: sum of squared differences divided by count of non-zero elements\n",
    "    col_variance = col_sum_sq_diff / col_count\n",
    "    \n",
    "    # Compute covariance: variance divided by mean (avoid division by zero)\n",
    "    epsilon = 1e-10  # Small value to prevent division by zero\n",
    "    col_covariance = (col_variance / (col_mean + epsilon))*100\n",
    "    \n",
    "    return col_mean, col_variance, col_covariance\n",
    "\n",
    "# Run the function\n",
    "mean, variance, covariance = sparse_mean_variance_covariance_csr(sparse_data)\n",
    "\n",
    "# Output the result\n",
    "print(\"Column-wise mean:\", mean)\n",
    "print(\"Column-wise variance:\", variance)\n",
    "print(\"Column-wise covariance (variance/mean):\", covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844ac29-f5d5-43a4-aff1-22ab5f641963",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column-wise mean:\", len(mean))\n",
    "print(\"Column-wise variance:\", len(variance))\n",
    "print(\"Column-wise covariance (variance/mean):\", len(covariance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd2d60-7f5c-4946-954e-f23e9dd5f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = pd.DataFrame({'mean':mean.get(),'variance':variance.get(),'covariance':covariance.get()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72498bc1-b6bd-489b-85ad-bb31e9d95f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=df_var, x='mean', y=\"covariance\", s=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
