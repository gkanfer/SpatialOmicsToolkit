{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084e8a57",
   "metadata": {},
   "source": [
    "<center> Advanced Integration and Annotation of scRNA-seq Data Using scVI: Hyperparameter Tuning, Label Transfer, and Custom Reference Creation - Part 2\n",
    "\n",
    "# Label Transfer and Hyperparameter Tuning\n",
    "\n",
    "Following successful integration and label transfer, the scVI model requires fine-tuning to optimize its performance. The `ModelTuner` function from the `scvi` module will be employed to adjust the neural network hyperparameters, ensuring accurate label transfer and robust integration.\n",
    "\n",
    "This step focuses on:\n",
    "\n",
    "- Improving classification accuracy of transferred labels.\n",
    "- Reducing batch effect noise while preserving biological signal.\n",
    "- Enhancing model generalizability for downstream analyses.\n",
    "\n",
    "Hyperparameter tuning will be performed using the `tune_hyperparameters()` method, enabling automatic selection of the best parameters based on a predefined metric (e.g., log-likelihood or classification accuracy). Once tuned, the model will be retrained on the full dataset. [GitHub reference](https://github.com/mousepixels/sanbomics_scripts/blob/main/sc2024/annotation_integration.ipynb)\n",
    "\n",
    "Next, we proceed with the implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scvi\n",
    "import torch\n",
    "#import celltypist\n",
    "#from celltypist import models\n",
    "from scvi.autotune import ModelTuner\n",
    "from ray import tune\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4743db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scvi-tools version:\", scvi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a318e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7d3f2",
   "metadata": {},
   "source": [
    "# Integration\n",
    "\n",
    "In this step, we will perform batch integration. It is essential to fine-tune the network for optimal predictions. The goal is to predict the latent space (hidden layer) of the network, and then perform K-Nearest Neighbors (KNN) and Leiden clustering on this layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a57625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the refferance data\n",
    "# andata_bc = andata_combined[andata_combined.obs['sample']=='ST'].copy()\n",
    "pathout = \"/data/kanferg/Sptial_Omics/SpatialOmicsToolkit/out_4\"\n",
    "andata_combined = sc.read_h5ad(os.path.join(pathout, \"adata_concat_BreastCancer_harmony_scVI_scANVI_unintigrated.h5ad\"))\n",
    "andata_bc = andata_combined[andata_combined.obs['sample']=='ST'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = scvi.model.SCVI\n",
    "model_cls.setup_anndata(andata_bc, categorical_covariate_keys = ['batch'],\n",
    "                             continuous_covariate_keys=['percent_mito'])\n",
    "tuner = ModelTuner(model_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd77a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tuner.fit(andata_bc, metric=\"validation_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cls(andata_bc)\n",
    "print(model.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450550ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_hidden\": tune.choice([92, 128]),\n",
    "    \"n_latent\": tune.choice([10, 20, 30, 40, 50, 60]),\n",
    "    #\"n_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"gene_likelihood\": tune.choice([\"nb\", \"zinb\"])\n",
    "}\n",
    "\n",
    "# Specify a storage path (e.g., a local directory for Ray's outputs)\n",
    "#run_config = RunConfig(storage_path=\"./ray_results\")\n",
    "\n",
    "# Run the tuner with the updated configuration\n",
    "results = tuner.fit(\n",
    "    andata_bc,\n",
    "    metric=\"validation_loss\",\n",
    "    resources={'gpu': 3},  # specify GPU resources\n",
    "    search_space=search_space,\n",
    "    num_samples=10,\n",
    "    max_epochs=2,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642aa247",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vl = 10000\n",
    "best_i = 0\n",
    "for i, res in enumerate(results.results):\n",
    "    vl = res.metrics['validation_loss']\n",
    "\n",
    "    if vl < best_vl:\n",
    "        best_vl = vl\n",
    "        best_i = i\n",
    "        \n",
    "results.results[best_i]\n",
    "\n",
    "print(f'{results.results[best_i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
